ğŸ“– MCP Search Tool with Mistral Summarizer
An interactive command-line search tool that combines SerpAPI web search with Mistral-7B Instruct model summarization. Built using the FastMCP framework for modular tool-based AI systems.



ğŸš€ Features
ğŸ” Search web queries using SerpAPI
ğŸ“‘ Summarize search results into clean, concise bullet points via Mistral-7B Instruct (Hugging Face Inference API)
ğŸ“¦ Modular client-server design with FastMCP
ğŸ“„ Environment variable management via .env (Hugging Face & SerpAPI keys)
ğŸ“¡ Async handling for efficient web requests and model calls



ğŸ“‚ Project Structure

search_mcp_project/
â”œâ”€â”€ client/
â”‚   â””â”€â”€ gemini_client.py    # MCP client implementation
â”œâ”€â”€ server/
â”‚   â””â”€â”€ search_server.py    # MCP server with SerpAPI integration
â”œâ”€â”€ .env                    # API keys (ignored via .gitignore)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”œâ”€â”€ README.md
â””â”€â”€ main.py                 # Entry point (if needed)




ğŸ› ï¸ Setup Instructions
1ï¸âƒ£ Clone the repository

git clone https://github.com/ayushiraj02/MCP_search-tool.git

cd MCP_search-tool


2ï¸âƒ£ Create a virtual environment
uv venv
source .venv/bin/activate


3ï¸âƒ£ Install dependencies
uv pip install -r requirements.txt  


4ï¸âƒ£ Configure environment variables
Create a .env file:
SERPAPI_KEY=your_serpapi_key_here
HF_TOKEN=your_huggingface_token_here


5ï¸âƒ£ Run the server
uv run server/search_server.py


6ï¸âƒ£ Run the client

In another terminal tab:
uv run client/gemini_client.py server/search_server.py


ğŸ“¸ Example Usage

ğŸ’¬ Mistral + MCP Client Started!
Type your queries (type 'quit' to exit).

ğŸ“ Query: top 10 news
ğŸŸ¢ Response:
â€¢ Japan hits record $232 billion M&A deals.
â€¢ 21 people killed in Gaza airstrikes.
â€¢ China responds to US fentanyl demands.
â€¢ France intercepts drones targeting Israel.
â€¢ India-US trade talks approaching July 9 deadline.







ğŸ“š Tech Stack
ğŸ Python 3.10+
ğŸ–¥ï¸ FastMCP
ğŸŒ SerpAPI
ğŸ¤– Hugging Face Inference API (Mistral-7B Instruct)
ğŸ“¦ uv package manager
ğŸ“„ dotenv for environment management



ğŸ“Œ To-Do / Future Improvements
 Add logging and error handling enhancements
 Support for multiple summarization models
 Dockerize the client-server system
 Add CLI argument parsing for query input


ğŸ“ License
This project is licensed under the MIT License.